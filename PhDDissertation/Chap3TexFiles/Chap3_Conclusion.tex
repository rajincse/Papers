
\section{Conclusions}
\label{sec:DOICollectionConclusion}
In visualizations that are open to instrumentation, gaze information provided by an eye-tracker can be used to automatically detect what visual objects users are likely to be viewing. Such detection can produce results that are almost as accurate as annotations created by human coders, provided that detection is done ``intelligently'', by using gaze points together with a prediction of which objects are likely to be viewed at a given time. Data collected in this way is highly granular and has semantic content because we link it to the data underlying the visualization. For this reason, and because it does not require any human pre-processing, we can efficiently collect and analyze object viewing data for many subjects, using interactive visualizations, for a long analytic session, and we could utilize it in studies that explore how analysts hypothesize about data using complex visual analytics systems. 