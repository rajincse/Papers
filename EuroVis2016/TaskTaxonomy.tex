\section{Task Taxonomy on DOI Timeline Visualization}
\label{sec:Taxonomy}

We present a task taxonomy for DOI analyses which we created by using Amar et al.'s taxonomy of visualization tasks~\cite{amar2005low} to exhaustively consider and organize questions that can be asked of DOI data collected from multiple subjects. We show a representative sample of tasks in Fig~\ref{fig:taxonomy}, and exemplify each task with specific questions based on the data, visualizations, and domains shown in Table~\ref{tab:ExampleDOI}.

Two principles emerged while exploring DOI tasks, allowing us to consider novel DOI tasks by generalizing from more familiar AOI tasks. First, while AOIs are typically identified by their identity (e.g., AOI 1), DOIs should be identified by constraints on their attributes and values (e.g., $DOI$ (type:`movie', name:`Dark Knight'). Furthermore, tasks targeting individual AOIs or DOIs should extend to selections of multiple DOIs defined by attribute constraints (e.g., DOI (type:`movie', $rating>8$)). For brevity, we will refer to such selections as DOI categories. Familiar AOI questions such as ``What $AOI$ has a user viewed at time $t$?'', ``When was $AOI_1$ viewed?'', and ``How prevalent is a transition from $AOI_1$ to $AOI_2$?'', then become ``What are the attributes of the $DOI$ viewed at time $t$?'', ``When was a given DOI category (i.e., DOIs with a certain configuration of attributes and values) viewed?'', and ``How prevalent are transitions between two DOI categories?''.

Second, analysis and data exploration should be possible at multiple levels of detail. Analysts should be able to ask questions about user behavior during time intervals ranging from seconds, to minutes, to hours, and query for individual DOIs or groups of DOIs. DOIs support such tasks since their attributes can be aggregated to answer questions about categories of data viewed during specific intervals (e.g., ``Did a user look at more comedies or more dramas?'', ``What is the average rating of movies viewed during an analysis?''). DOI attributes can also be queried to create flexible selections of DOIs and use these to work at higher levels of abstraction. All DOIs tasks should be possible for one or more subjects, and for flexibly defined time intervals (e.g., ``first half of the user's analysis'', ``the last five minutes of analysis'').

After considering a wide range of tasks and similarities between them, we decided to divide them into four categories that broadly define the high-level questions that analysts can ask of DOI data. Our first category, ``Summarize'', includes tasks aimed at capturing what types of data subjects were interested in during the whole or part of an experiment, and computing derived values from attributes of viewed DOIs.  The second category, ``Type of data over time'', includes questions that reveal temporal patterns in users' data interests. As noted previously, such tasks should support multiple time-scales and time intervals. Tasks in our third category, ``DOI transitions and sequences'', are intended to facilitate insights into how DOIs are viewed together. In line with the desideratum for multi-granular analyses, such tasks should go beyond exploring just direct transitions between pairs of DOIs, and instead look at broader groups and sequences of DOIs that are viewed together. Moreover, given that granular DOI detection is probabilistic and less robust than course AOI methods, analyses should be tolerant to small variations or `errors' in users' viewing patterns (see task 13). Our fourth category, ``Compare, contrast, and correlate'', capture tasks that allow analysts to compare either groups of users (e.g., novice vs. novice users), or time intervals (e.g., early in an analysis vs. late in an analysis).

For added detail that goes beyond our four broad categories, we also show how tasks relate to Amar et al.'s ten generic visualization task categories: Retrieve Value, Filter, Compute Derived Value, Find Extremum, Sort, Determine Range, Characterize Distribution, Find Anomalies, Cluster, Correlate. As is usual in task taxonomies, some tasks overlap or are higher level tasks that could be implemented with lower level tasks (e.g., multiple user tasks could be implemented with single user properties). However we added them to emphasize that such tasks such be supported efficiently as stand-alone tasks.

\begin{figure*}[!htb]
  \centering
  \includegraphics[width=\linewidth]{images/DOITask.eps}
  \caption{Task taxonomy list for DOI-based analysis. }
	\label{fig:taxonomy}
\end{figure*}
