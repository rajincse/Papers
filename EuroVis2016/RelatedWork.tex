\section{Related Work}
Eye tracking is an effective mechanism to inspect people's visual patterns and attention processes~\cite{jacob1991use}, and is widely used is fields such as psychology, neuroscience, human-computer interaction, and data visualization~\cite{duchowski2002breadth} to investigate how people perceive, react to, and think with visual stimuli. In a traditional eye-tracking user study, a human subject performs visual tasks in front of a computer screen attached with an eye-tracking device. For example, eye-tracking experiments were undertaken to study how people recognize faces~\cite{guo2014perceiving}, attention pattern linked with physical discomforts~\cite{vervoort2013attentional}, and how students learn graphical contents~\cite{mayer2010unique}. Moreover, contributions using eye-tracking within data visualization field include, among others, studies on graph readability~\cite{pohl2009comparing, huang2008beyond, huang2005people}, tree-drawing perception~\cite{burch2011evaluation, burch2013visual}, and visualization evaluation~\cite{kim2012does}.  The breadth and scope of eye tracking research is growing rapidly as eye-trackers become increasingly accurate, fast, and affordable.  

Eye-tracking data is generally analyzed using one of two approaches: point-based and area-of-interest (AOI)-based~\cite{blascheck2014state}. Point-based analyses consider gaze samples individually albeit AOI analyses accumulate gazes into areas of interests and then administer at this high abstraction level. 

Traditionally, analysts define AOIs manually over stimuli although automatic AOI defining is possible using gaze-clustering algorithms over available eye-tracking data~\cite{privitera2000algorithms, santella2004robust, drusch2014analysing}. Our work is adjoining to the methods of relating gazes automatically to the semantics of the underlying data that generate visual stimuli. Steichen et al.~\cite{steichen2013user}, and Kurzhals et al.'s work~\cite{kurzhals2014iseecube} implies that AOIs can be dynamically defined for such circumstances. Albeit, their work neither formalize any procedures nor compute feasibility. More precisely, for dynamic 3D stimuli, Stellmach et al. introduced the concept of object of interests (OOI) where gazes can be accumulated to 3D objects in the scene~\cite{stellmach20103d}. Moreover, Bernhard et al. proposed identical gaze-to-object mapping (GTOM) in the context of comprehending people's perception to objects in 3D environments~\cite{bernhard2014gaze}. 

Recently, we proposed feasibility of automatically relating gazes to semantic contents of a regular 2D information visualization using DOI-based analysis. We also described, the practicability of instrumenting source code of generating visualization to generate DOIs in run-time. We compared the automatic DOI-based approach with conventional manual approach for analyzing eye-tracking data and the results show that the automatic DOI-based analysis data were similar to manual analysis data.

The concept of DOI is similar to mapping gazes to semantic information from Game engines~\cite{sundstedt2013visual}. Albeit, typical information visualization does not have access to such game engines. Moreover, our work differs from gaze analysis of 3D games on the concept of instrumentation and dynamic analysis. 

Plenty of visualization and visual analytics tools exist for both point-based and AOI-based eye-tracking analysis. Blascheck et al. presented an exhaustive survey of such methods~\cite{blascheck2014state}. Since DOI is analogue to AOI, visualization methods for AOI analyses are most pertinent to our work. Examples of such methods include scanpaths, scarf-plots, AOI-rivers and AOI transition matrices. Moreover, visual analytics principles and systems for AOI data is also relevant to our work. Such analytics principles are proposed by Andrienko et al.~\cite{andrienko2012visual}, Weibel et al.~\cite{weibel2012let}, and Kurzhals et al.~\cite{kurzhals2014iseecube}. 

To analyze DOI data with existing visualization techniques, analysts are required to perform some visual tasks. Visual tasks may vary depending on the data type used to generate visualizations. Shneiderman described a high level task taxonomy over different types of data such as 1D, 2D, 3D, temporal, multi-dimensional, and network~\cite{shneiderman1996eyes}. Moreover, Brehmer et al. recently proposed multi-level typology that can be aided to create a complete task description~\cite{brehmer2013multi}. Amar et al. proposed ten low-level visual-analytics tasks types as questions experimenters may ask while performing experiments with tabular data~\cite{amar2005low}. Finally, task taxonomies exist for some specific categories of visualizations, such as graph visualization~\cite{lee2006task}, group-level graph~\cite{saket2014group}, and multidimensional data visualization~\cite{ward2002taxonomy}. However, task taxonomy exist neither for AOI data nor DOI data. In this paper, we proposed a task taxonomy specific to DOI data which will aid analysts to perform DOI-based visualization. Moreover, The focus of the work to establish DOI-based a feasible analysis method for eye-tracking data, and provide a formal definition, task taxonomies and visualization techniques for DOI-based analysis. 

