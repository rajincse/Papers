\section{A visual design space for DOI analysis}
The previous sections highlighted the differences between AOI and DOI data, and illustrated the broad range of DOI enabled tasks. This provides an intuition that methods previously developed for AOI analysis do not directly extend to DOI data. First, AOI visualizations such as scanpaths, scarfplots, and AOI-rivers cannot handle the scale of DOI data, which is captured at high granularities and over extended periods of time. Second, AOI visualizations were not designed to show or leverage the many attributes that can typically characterize DOIs.  Third, collecting users' interest in richly annotated DOIs over hour long analysis and from many users can support analytic workflows different from those typical of AOI analyses. This section explores a design space of visual solutions that can alleviate these shortcomings.

Broadly, novel visualizations need to allow analysts to explore DOI data at multiple levels of detail, including a range of temporal scales (e.g., several seconds vs. several minutes) and data granularities (e.g., individual DOIs vs. categories of DOIs).  Moreover, attributes need to be shown visually and queried flexibly to allow analyzers to identify links between users' interest in data and that data's properties. DOIs attributes should be leveraged to help deal with the scale of the data by allowing users to filter, highlight, and aggregate data with specific attribute configurations. Finally, visual analyses need to support the particular tasks that DOIs support (section~\ref{sec:Taxonomy}). 

In the following sections we analyze the design space for visual DOI analysis in more detail. Given the scale and complexity of DOI data and the breadth of tasks, visual encodings need to be augmented with significant interaction capabilities. To ensure that our discussion is exhaustive and captures all visual design dimensions, we ground it in Yi's taxonomy of interaction tasks~\cite{yi2007toward}, which includes seven categories of visual design coordinates: Encoding, Selection, Reconfiguration, Exploration, Abstraction/Elaboration, Filtering, and Connection/Comparison~\cite{yi2007toward}. Moreover, to leverage a familiar frame of reference, we will discuss novel visual solutions by starting from existing AOI visualizations and describing how they may be extended and redesigned to support DOI requirements. For a more compact organization, we group encoding principles separately from interaction principles.
 

\subsection{Encoding}
\label{sec:Encoding}
Encoding determines how data should be represented visually~\cite{yi2007toward}. Encodings of DOI data need to scale to many DOIs viewed over long periods of time, be able to show data at multiple scales of time and data granularity, show DOI attributes and leverage them to improve legibility, and support the tasks exemplified in section~\ref{sec:Taxonomy}. Encodings should as much as possible support tasks visually, rather than rely extensively on interactions such as navigation or information on demand.

\textbf{Showing many DOIs :} First, some AOI visualizations such as scarfplots and AOI rivers identify individual AOIs through distinctive colors. This method does not scale to hundreds of granular DOIs that users can view during long experiments. Methods that identify DOIs explicitly (e.g., through a label), such as scanpaths or transition matrices, are thus preferable. 

Second, showing all DOIs viewed during an experiment is not always possible, especially when analyzing data from multiple users. For example, a scan-path of ten users, each having viewed approximately one hundred DOIs would need to show a thousand rows and would be extremely cluttered. A solution is to show only the top data and scale data based on how much it was viewed. This is likely to give good results as Alam et al. has shown that even though users view many things, they tend to focus predominantly on a few that are relevant to their momentary goals or analyses. This prioritization can be combined with an ability to specify a time-window of interest, as shown in Figure X, and described in more detail in section X. 

Third, DOI attributes make it possible to aggregate multiple DOIs into categories to reduce the amount of information shown. Such aggregations can be done semantically, by allowing analysts to explicitly collapse multiple DOIs into single ones, such as in hierarchical visualizations for instance~\cite{kurzhals2014iseecube}, or visually, by showing all data in a way that allows categories to emerge and separate, such as for example in pixel based techniques~\cite{keim2000designing}.

\textbf{Showing long experiments :} Showing time at multiple resolutions and restricting views to time windows are addressed in sections X and Y and rely on the ability to show data that is aggregated over times longer than a single fixation. Again, temporal-zooming can be semantic, by aggregating and summarizing data over longer time-steps, or visual, by allowing individual viewing-events to merge and blend together visually. Such visual encodings are difficult to imagine in traditional scan-paths or scarfplots as they depict direct transitions between objects at a temporal resolution of one fixation. Instead, the heatmap view in Figure X, and the reimagined scarfplot show in Figure Y can support multiple time resolutions. AOI-rivers support longer time resolutions too, but do not scale down to show individual DOI events and transitions.

\textbf{Showing attributes :} DOI attributes can be shown using conventional encoding principles such as linking attributes to visual channels (e.g., color, shape) or by relying on glyphs~\cite{maguire2012taxonomy}. 

\textbf{Reducing clutter :}
Showing many DOIs and condensing time generally results in busy visual encodings that need to be optimized to reduce clutter. First, clustering is an effective way to impose order on visualizations. Figure X shows a scarfplot that orders DOIs randomly as compared to one in which DOIs are clustered by how often there are transitions between them, a process which results in shorter scan-path lines between DOIs. Similarly, clustering by user behavior can create more organized visualizations, while clustering and arranging DOIs based on their attributes may support tasks such as [t1..t2]. Second, linking DOI appearance to their attributes can divide DOIs into visual categories or layers separable in accordance with Gestalt principles. Further dividing DOIs by how often they were viewed may achieve similar effects.  Finally, reducing the information shown using semantic zooming and DOI grouping, as described before, can also reduce clutter. 

\textbf{Supporting tasks :}
Showing multiple types of attributes concurrently for each DOI, as described previously, would make it possible to visually identify categories of DOIs, an important part of tasks described in section X, and would facilitate a visual approximation of DOI derived measures (tasks X - Y). 

Moreover, being able to visually detect clusters of DOIs with similar properties would allow analysts to detect correlations between DOI categories, times they were viewed (e.g., time tasks X,y,z), and combinations they were viewed in (e.g., transition tasks X,Y,Z). For such visual tasks to be possible however, it's not sufficient to show many DOI attributes. Additionally, DOIs need to be grouped based on when they were viewed or in what transitions they were involved. For example, scarfplots inherently group DOIs by the when they were viewed (Figure X), but the scan-path and transition matrix in Figure X and Y had to be clustered to visually group DOIs that were viewed together or around the same time. 

To support tasks X-Y[transition tasks], transition matrices should allow for  variable definitions of transitions. The mockup design in Figure X, illustrates how transitions could be specified as either the viewing of one object immediately after another, but also as the viewing of an object within a time interval of another, or within multiple transitions. Furthermore, we hypothesize that in the context of DOIs, transition graphs such as that shown in Figure X could better show DOI sequences (tasks X,Y,Z) given that node-link diagrams are significantly better at showing paths than are matrices~\cite{ghoniem2004comparison,okoe15ecological}.  Moreover, networks may directly capture different definitions of transitions visually by placing DOIs closer or farther apart, with more or less edges between them, depending on how close together DOI were viewed. 

A further factor needs to be considered when supporting analyses of many users. While AOI analyses often rely on few AOIs that most subjects view, data-sets can support hundreds of DOIs, which subjects, based on their interests and exploration, will only see small subsets of. These subsets may differ significantly between subjects, leading to an important tradeoff: should visualizations be optimized to best show a single user's behavior, or to show a user's behavior in the context of other users' behavior? Consider the two scan-paths in Figure X. The one on the left displays the top twenty DOIs each user viewed, ordered by how much the user viewed them. The one on the right was built by considering which DOIs were viewed most by all subjects, and uses this same DOI-set and ordering for each users. The first approach shows more relevant data for each user, but makes it difficult to compare users' data. The latter shows less relevant data for each user, but the similar visual ordering makes it easy to compare user behavior. Similarly, scan-paths can be grouped by users or by DOIs as shown in Figure X. The first one makes it more clear to see [what], while the later is better for [what].

\subsection{Interaction}
\textbf{Selection :}
Selections allow users to mark interesting objects to keep track of them~\cite{yi2007toward}. With respect to selection targets, visualizations should support DOI tasks by enabling selections of DOIs, DOI categories, users and groups of users, and time windows.  As for methods of selection, two options are possible: `in situ' selections of DOIs shown in the visualization, and query based selections of DOIs based on their attributes. Finally, selected items should be highlighted visually and brushing and linking should correlate selections over multiple views, supporting connect and compare interactions described later. Figures X-Y exemplify DOI selections, time-window selections, and brushing and linking operations.
	
\textbf{Reconfiguration :}
Reconfigurations provide users with different perspectives of their data by changing the spatial arrangement of data~\cite{yi2007toward}.  In section~\ref{sec:Encoding} we already discussed the benefits of clustering and ordering DOIs based on their transitions, and users based on their overall visual behavior. Additionally, DOIs should be orderable based on their attributes (e.g., the scan-path in Figure X orders DOIs by their type), and visualizations should support manual repositioning and reordering (e.g., of users, of DOIs).

\textbf{Exploration :} 
Exploration enables users to analyze different subsets of data instances~\cite{yi2007toward}. Given the scale and granularity of DOI data, visualizations should support time-scrolling and panning, and zooming efficiently. Further exploration should include the ability to flexibly define which DOI attributes should be mapped visually, given that the number of variables that can be encoded visually is generally limited. 
	
\textbf{Abstract/Elaborate :} 
Abstract/Elaborate interactions allow users to control a visualization's level of abstraction. Our discussion on encoding emphasizes the need for representations that support analyses at multiple time-scales, DOI grouping, and the ability to control the amount of data shown. Semantic zooming can be an efficient way to explore different time scales. For example, the heatmap in Figure X goes beyond fixations and shows data at a resolution of several seconds.  DOIs could be grouped by using attribute queries to define DOI categories, by exploiting DOI hierarchies (i.e., DOIs that are contained by other DOIs) supported by the DOI data model (section~\ref{sec:DataModel}), or manually. The amount of data shown could be controlled by analysts either directly (e.g., ``Show top $25\%$ most viewed data''), or by adjusting the space allotted to individual or all users and viewing as much data as can be fitted in that space. Finally, details on demand should provide access to additional data by using tool-tips and auxiliary information data panels, populated with data obtained by brushing and linking.
	
	
\textbf{Filtering}
Filter interactions enable users to change the set of data items being presented based on specific conditions. Filtering should be possible on all selectable data categories (see above). DOIs should be hidden or revealed based on their attributes, how often they are viewed, when they are viewed, and which users view them (e.g., ``Show only DOIs that both of two selected users viewed''). Analysts should also have the option to filter out data pertaining to individual users and groups of users. 

Defining time-windows of interest can significantly support both reconfiguration and filtering interactions. Since DOI visualizations will likely prioritize which data to show and order it based on temporal patterns, defining specific time windows that such configurations should be based on can significantly impact visual representations and support interesting questions. For example, by prioritizing data subjects viewed late in an experiment, an analysts could unclutter the visualization of data that subjects viewed during preliminary exploration and search processes, and more clearly reveal how their final data interests crystalized. 
	
\textbf{Connection/Comparison}
Connection interactions show associations and relationships between represented data items~\cite{yi2007toward}.  To support comparisons of multiple users (tasks X-Y) visualizations should implement one of the Gleicher et al.'s three methods for visual comparison: juxtaposition, superpositiion, and explicit encoding of differences. To support juxtaposition, data from multiple users or from multiple time-intervals should be visualized in compact, stackable, and comparable ways. The scarfplot and heatmap designs in Figure X and Y suggest that they can be resized to show more or less of a user's data and thus accommodate multiple users within a single screen; and the scarf-plot in Figure X uses the same DOI ordering for all users to ensure that they are easily comparable. Moreover, the options to reorder and rearrange subjects' data (section X), and to hide time intervals, would allow data to be compared to be brought close together. Superposition is supported by visualizations such as scan-paths (Figure X), and could be supported in transition-graphs through the use of multi-edges. Selecting and highlighting overlaps and differences (e.g., ``Show DOIs viewed by all participants'', ``Show DOIs that are unique to a subject'') can implement the third method of comparison. Brushing and linking across users and across time would support all comparison and correlation tasks.

 Finally, clustering can reveal similarities between users or time-intervals and group them close together. AOI sequences of multiple users have been previously clustered using a string-edit distance~\cite{kurzhals2014iseecube}. This gave good results for short, highly constrained perceptual tasks with few AOIs. However, we think this distance measure is not robust enough to handle DOI data collected over long, open-ended tasks, since such data is not temporally-aligned and bound to always differ at the key-hole level that string-editing operates. Comparing users in a space of derived features (e.g., DOIs they viewed most, common DOI transitions or sequences) may be more robust to local differences, and would additionally allow features to be included in and excluded from a distance measure, thus enabling an exploration of which features can explain hypothesized behavior.


