\section{Visual Methods}
Yi et al. discuss about the dichotomy between visual encoding and interaction~\cite{yi2007toward}. While AOI visualization technique do not focus much on interaction, we have an intuition that with the scale and granularity of DOI data this will become important. Current AOIs do not support the scale and granularity of DOIs and they can not support some of the novel tasks that DOI enable. 

Exploring a design space for visualization that can support DOI tasks in its entirety is difficult. We organize it by Yi's taxonomy of interaction tasks~\cite{yi2007toward}. Moreover, novel visual encodings could be proposed but that is a research effort in its own right. Instead, we will center our discussion on how AOI visualizations need to be changed to support DOI characteristics; but principle we discuss could be incorporated in any new visualizations as well.

In Section~\ref{sec:FormalDOIModel}, we model DOIs as data elements with multiple attributes. In a visual encoding, tuning resolutions of those attributes may change the representation of the data. For example, eye-tracking data generally contains a timestamps along with the gaze positions. Applying a DOI analysis over eye-tracking data eventually generate DOIs with timestamps. In a small time duration small number of DOIs will be generated. Moreover, DOIs count will increase rapidly with the duration. Such cases may require filtrations or alternate visual encodings. Furthermore, flexible operations may be applicable to DOI attributes. For example, a DOI data from movie domain may contain movies with attributes: $<title, rating>$. Incorporating interaction such as filtration over $rating$ ( e.g. $5 \leq rating \leq 7.5 $) may create different representation of the data.

\subsection{Visual Encoding}
Blascheck et al. listed visual encoding for AOI data such as scanpaths, scarf-plots, rivers and transition matrices~\cite{blascheck2014state}. DOI data is a highly granular and annotated AOI data at core. Hence, AOI visualization encodings may be appropriate to DOI data. We hypothesize that, visual encodings for AOI data is insufficient for DOI data. First, visual encodings are required to support high scalability of DOI. For example, DOI data collected from an eye-tracking study with hour-long sessions, more than ten users, and highly granulated DOI definition will end up having thousands of DOI units. Visual encoding such as AOI-river will be unsuitable for such cases as cardinality of AOIs is a limitation~\cite{burch2013aoi}. Second, displaying and leveraging attributes are required to visual encodings. Finally, visual encodings required to support some tasks which is not possible in AOIs. AOI techniques can be applied in all cases directly and augmented by interactions. For example, hovering over a scarfplot items could show details in textual forms which is not reasonable. Moreover, the encoding itself should support some of the tasks. For example, multiple objects viewing at the same time is possible either because we do not know what a user looks at or because we are aggregating over larger time steps.

Some modification may be applicable to DOI visual encodings. We discuss some of them below. 
\begin{itemize}
	\item \textbf{Showing identity:} Showing identity of visual elements will facilitate representing DOI data. Although, some AOIs visualizations already do that (e.g. AOI-river) but some do not (e.g. scarfplot) resulting requirement of modifications.
	\item \textbf{Displaying attributes:} Some encoding variables can be modified to display attributes such as color, shapes. Moreover, visual encodings may employ glyphs to display attributes.
	\item \textbf{Visual clustering support:} Support visual clustering would benefit DOI visualization. For example, in a scarfplot visualization, clustering over visual elements with same category or similar attribute may decrease visual clutters. Moreover, in a scanpath DOIs with numerous transitions can be clustered together to make the visualization reasonable. 
	\item \textbf{Showing only ``top'' data:} We found that interest in data decays exponentially with its relevance to a task; as such, not all DOIs are equal. Some DOIs will be viewed for only a fraction of a second, while others will be viewed multiple times for many seconds. 
	\item \textbf{Showing semantic filtering/zooming:} Granularity of DOIs can be negotiated using semantic filtering or zooming by showing more or less data depending on the zoom level.
	\item \textbf{Support grouping:} Grouping is possible either by grouping DOIs by attribute or grouping users by calculating similarity index among them over DOI data. Moreover, some encodings (e.g. AOI river, transition matrices) exist for aggregated users by considering all users as a single user via condensing and aligning. 
\end{itemize}


  %maybe we can talk briefly about novel encodings: the existence of attributes allows to maybe come up with new visualizations (Examples)
%
  %matrices are somewhat problematic in the world of fuzzy transitions (we sometimes don't know for sure which object was viewed) and in the world of large scale analysis in which a user
  %might get to an intended object but quickly glance on something else on the way; in other words looking at groupings (rather than seequences) or sequences that allow for wildcards (see VA2);
  %note that matrices are not good a detecting graphs and it is also more difficult to encode how much an object was viewed (an example would be great)
  %-maybe graphs would be better? they could capture 
\subsection{Interactions}
Interactions over a visualization permits to choose appropriate representations. Yi et al. proposed seven categories of interactions based on the concept of user's aim to a visual task: Selection, Encoding, Reconfiguration, Exploration, Abstraction/Elaboration, Filtration, and Connection~\cite{yi2007toward}. 

\begin{itemize}

	\item \textbf{Selection:} Selection interaction is used to make visual element relatively more salient. Selection interaction can make a visual element distinct from other elements. For example, multiple view of a DOI data may have brushing and linking interaction to compare within a single user or across users. Selection is possible within DOI by identity, attribute, or by user.
	
	\item \textbf{Encoding:} Encoding interaction triggers a visualization morph to a new representation. This interaction enables users to choose among different representation discussed above. Moreover, encoding interaction is used to change shape, size, and color of a visual element. For example, scanpath representation of a multi-user DOI data can have vertically juxtaposed form and super-positioned form. A user can choose either of the representation using a drop-down list, based on the number of subject the data contains. Moreover, label-colors, size, and shape of the time-span mark can be changed using encoding interaction. 
	
	\item \textbf{Reconfiguration:} Reconfiguration interaction enables arranging visual elements to a different positions. For example, a multi-user supported scanpath  may have orderings of line-trajectories by DOIs or by users. First, DOIs within scanpaths may have ordering depending on attributes either on attribute value or attribute category. Such ordering may be computed over an individual user or all users. Next, ordering by users is possible using methods such as clustering over certain DOI properties, order by user properties, or manual ordering.
	
	\item \textbf{Exploration:} Exploration interaction is essential for over sized representations. Panning is one of the most common techniques. Coupling selection with exploration may enable users to stroll through the data from a relative point. For example, in scanpath visualization with huge number of DOIs can be explored by panning. Moreover, user can select a particular DOI and explore its changes of interest over time. 
	
		\item \textbf{Abstraction/Elaboration:} Abstraction interaction facilitates to display fewer visual elements. Further, elaboration displays more visual elements. These interactions facilitate multi level of granularity for DOI. Zooming out and in is a common form of abstraction/elaboration. Displaying more or less data over DOI data is possible using few techniques. First, adjusting the space allotted to each user data may facilitate showing as much data as possible for each user data. Second, by specifying how much data to show can control this interaction. Third, controlling time scales may reveal or hide data on visualization such as AOI-rivers, scarfplots, or  heatmaps. Third, computing hierarchy among DOIs enables collapsing and expanding within visualizations which is supported in most of the AOI-based visualizations. Finally, details on demand interaction can be used to achieve such interaction (e.g. mouse over DOIs or users).
	
	
	\item \textbf{Filtration:} Decreasing DOI count in a visualization is a significant requirement. Filtration interaction enables users to display visual elements conditionally. For example, DOIs are defined with an attribute $score_{gaze}$ where $0 \leq score_{gaze} \leq 1$. Using filtration technique, user can regulate a threshold $T$ such as $score_{gaze} \geq T$. Assigning  value closed to the maximum value for $T$ ( e.g. $T =0.85$) would result relatively tiny number of DOIs. Additionally, for temporal aspect of DOI data, filtration is possible by specifying time frames. 	

	
	\item \textbf{Connection:} Connection interactions shows related items of visual elements. Connection can also be coupled with selection. For example, in a scanpath visualization when user selects a perpendicular line for a DOI, the related DOI perpendicular lines get highlighted. Multiple views over same data can be displayed using juxtaposition, super-positions, and explicit encodings~\cite{gleicher2011visual}. Brushing and linking over juxtaposed views can connect DOI objects. Moreover, using super-position and explicit encoding can be relatively hard to connect DOI objects. 
\end{itemize}



