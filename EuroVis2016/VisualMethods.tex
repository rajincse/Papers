\section{A visual design space for DOI analysis}
The previous sections emphasize the differences between AOI and DOI data and provide an intuition that visual methods that have been developed for AOI analysis do not automatically extend to DOI data. Broadly, AOI visualizations such as Scanpaths, Scarfplot , and AOI-river cannot handle the scale of DOI data, which is captured at high granularities and over extended periods of time. To address this, novel visualizations will need to allow analysts to explore DOI data at multiple levels of detail, including a range of temporal scales (e.g., several seconds vs. several minutes) and data granularities (e.g., individual data objects vs. classes of objects).  
AOI visualizations were also not designed to show or leverage the attributes that are typical of DOIs.  Attributes need to be shown visually and queries flexibly to allow analyzers to identify links between users' interest in data and that data's properties. They can also be leveraged to help deal with the scale of the data by allowing users to filter, highlight, and aggregate data with specific attribute configurations.
Finally, collecting users' interest in richly annotated DOIs over hour long analysis and from many users can support analytic workflows different from those typical of AOI analyses. For example, analysts may care less about individual DOIs and more about groups of DOIs defined by their attributes and they may explore larger temporal scales rather than individual viewing transitions between DOIs. The task taxonomy described in Section~\ref{sec:Taxonomy} illustrate such tasks, and visual methods should be geared towards supporting them. 
In the following sections we explore a design space for visual DOI analysis in more detail. We hypothesize that given the scale and complexity of DOI data, interaction will play a significant role in analyzing it. As such, we treat both visual encoding and interaction design in equal parts. Moreover, our goal is not to propose novel visual encodings, which would be a research effort in its own right, but to discuss general design principles that apply to visual DOI data analyses. As such, we considered it practical to ground our discussion by using variations of AOI visualizations to exemplify what functionality needs to be implemented and how it could be implemented. 
To ensure that our discussion is exhaustive and captures all design dimensions, we organize it by Yi's taxonomy of interaction tasks~\cite{yi2007toward}. Yi et al. proposed seven categories of interactions based on the concept of user's aim to a visual task: Selection, Encoding, Reconfiguration, Exploration, Abstraction/Elaboration, Filtration, and Connection~\cite{yi2007toward}. 
\subsection{Encoding}
Blascheck et al. listed visual encoding for AOI data such as scanpaths, scarf-plots, rivers and transition matrices~\cite{blascheck2014state}. DOI data is a highly granular and annotated AOI data at core. Hence, AOI visualization encodings may be appropriate to DOI data. We hypothesize that, visual encodings for AOI data is insufficient for DOI data. First, visual encodings are required to support high scalability of DOI. For example, DOI data collected from an eye-tracking study with hour-long sessions, more than ten users, and highly granulated DOI definition will end up having thousands of DOI units. Visual encoding such as AOI-river will be unsuitable for such cases as cardinality of AOIs is a limitation~\cite{burch2013aoi}. Second, displaying and leveraging attributes are required to visual encodings. Finally, visual encodings required to support some tasks which is not possible in AOIs. AOI techniques can be applied in all cases directly and augmented by interactions. For example, hovering over a scarfplot items could show details in textual forms which is not reasonable. Moreover, the encoding itself should support some of the tasks. For example, multiple objects viewing at the same time is possible either because we do not know what a user looks at or because we are aggregating over larger time steps.

Some modification may be applicable to DOI visual encodings. We discuss some of them below. 
\begin{itemize}
	\item \textbf{Showing identity:} Showing identity of visual elements will facilitate representing DOI data. Although, some AOIs visualizations already do that (e.g. AOI-river) but some do not (e.g. scarfplot) resulting requirement of modifications.
	\item \textbf{Displaying attributes:} Some encoding variables can be modified to display attributes such as color, shapes. Moreover, visual encodings may employ glyphs to display attributes.
	\item \textbf{Visual clustering support:} Support visual clustering would benefit DOI visualization. For example, in a scarfplot visualization, clustering over visual elements with same category or similar attribute may decrease visual clutters. Moreover, in a scanpath DOIs with numerous transitions can be clustered together to make the visualization reasonable. 
	\item \textbf{Showing only ``top'' data:} We found that interest in data decays exponentially with its relevance to a task; as such, not all DOIs are equal. Some DOIs will be viewed for only a fraction of a second, while others will be viewed multiple times for many seconds. 
	\item \textbf{Showing semantic filtering/zooming:} Granularity of DOIs can be negotiated using semantic filtering or zooming by showing more or less data depending on the zoom level.
	\item \textbf{Support grouping:} Grouping is possible either by grouping DOIs by attribute or grouping users by calculating similarity index among them over DOI data. Moreover, some encodings (e.g. AOI river, transition matrices) exist for aggregated users by considering all users as a single user via condensing and aligning. 
\end{itemize}
\subsection{Selection}
Selection interaction is used to make visual element relatively more salient. Selection interaction can make a visual element distinct from other elements. It can also implement brushing and linking across multiple data views or user datasets, aiding in comparison tasks. 
Selection is possible within DOI by identity, attribute, or by user.
	
	
\subsection{Reconfiguration:} Reconfigurations allow users to see different perspectives of the their data. For example, a multi-user supported scanpath  may have orderings of line-trajectories by DOIs or by users. First, DOIs within scanpaths may have ordering depending on attributes either on attribute value or attribute category. Such ordering may be computed over an individual user or all users. Next, ordering by users is possible using methods such as clustering over certain DOI properties, order by user properties, or manual ordering.
\subsection{Exploration:} Exploration interaction is essential for over sized representations. Panning is one of the most common techniques. Coupling selection with exploration may enable users to stroll through the data from a relative point. For example, in scanpath visualization with huge number of DOIs can be explored by panning. Moreover, user can select a particular DOI and explore its changes of interest over time. 
	
\subsection{Abstraction/Elaboration:} Abstraction interaction facilitates to display fewer visual elements. Further, elaboration displays more visual elements. These interactions facilitate multi level of granularity for DOI. Zooming out and in is a common form of abstraction/elaboration. Displaying more or less data over DOI data is possible using few techniques. First, adjusting the space allotted to each user data may facilitate showing as much data as possible for each user data. Second, by specifying how much data to show can control this interaction. Third, controlling time scales may reveal or hide data on visualization such as AOI-rivers, scarfplots, or  heatmaps. Third, computing hierarchy among DOIs enables collapsing and expanding within visualizations which is supported in most of the AOI-based visualizations. Finally, details on demand interaction can be used to achieve such interaction (e.g. mouse over DOIs or users).
	
	
\subsection{Filtration} Decreasing DOI count in a visualization is a significant requirement. Filtration interaction enables users to display visual elements conditionally. For example, DOIs are defined with an attribute $score_{gaze}$ where $0 \leq score_{gaze} \leq 1$. Using filtration technique, user can regulate a threshold $T$ such as $score_{gaze} \geq T$. Assigning  value closed to the maximum value for $T$ ( e.g. $T =0.85$) would result relatively tiny number of DOIs. Additionally, for temporal aspect of DOI data, filtration is possible by specifying time frames. 	

	
	\subsection{Connection and comparison} Yu defines connections as â€¦. We include comparison as a separate design consideration, as comparison is essential in experimental studies and thus in analyses of eye-tracking data. Connection can also be coupled with selection. For example, in a scanpath visualization when user selects a perpendicular line for a DOI, the related DOI perpendicular lines get highlighted. Multiple views over same data can be displayed using juxtaposition, super-positions, and explicit encodings~\cite{gleicher2011visual}. Brushing and linking over juxtaposed views can connect DOI objects. Moreover, using super-position and explicit encoding can be relatively hard to connect DOI objects. 
