\section{Introduction}
Eye-tracking devices report users' gaze positions on a screen. Typical eye-tracking user studies record gaze positions of subjects performing visual tasks. Eye-tracking has broad usage as a diagnostic tool in psychology, cognitive sciences, human-computer interaction, and visualization research~\cite{duchowski2002breadth}.

Traditionally, eye-tracking data is analyzed offline by human analysts using one of two approaches: point-based analysis and Area of Interest (AOI)-based analysis~\cite{blascheck2014state}. Point-based techniques treat fixations as individual units of analysis and can reveal the distribution or sequence of fixations over visual stimuli (e.g. gaze heatmaps, scanpaths). AOI-based techniques rely on a preliminary annotation of visual stimuli with AOIs, image regions of interest with particular semantic meaning.  Both approaches require significant data annotation and interpretation efforts and are prohibitively time-consuming in studies involving multiple users, long sessions, and interactive stimuli. 

Recently, we described Data of Interest (DOI) analysis of eye-tracking data, an approach building on Stellmach et al.'s ``OOI''~\cite{stellmach20103d}, and Papenmeier et al.'s ``DynAOI''~\cite{papenmeier2010dynaoi} approaches, as an alternative to traditional point based and AOI-based analyses. When visual content is dynamically generated, such as for data visualizations, the structures of the visual content is known at rendering time.  In such cases, the source code can be instrumented to match gaze coordinates from an eye-tracker to visual items rendered by the visualization on the screen, and implicitly to the underlying data, in real-time. For example, the code of a node-link visualization can be instrumented to correlate gaze-coordinates to positions of individual nodes and automatically report which nodes subjects are viewing at any time.  We showed that DOI data is accurate and that the overhead of instrumenting visual systems to capture DOI data is relatively low. 

Once a visualization instrumented, DOI data can be collected automatically, without additional effort, any number of users and any length of time. Also, gazes are mapped to data, irrespective of specific views that subjects saw and individual interactions that generated those views. Also, once a system instrumented, DOI data can be collected without additional overhead for any dataset supported by that visualizations.

We will show that these processes lead to novel data. While DOIs are analogue to AOIs defined in data space, there are significant differences both in the properties of the data and the questions that it can answer. DOI data is significantly larger in scale (collected over long periods of time), more granular (individual data elements rather than viewers or large screen portions), and DOI derive properties from the underlying data model and which can be used in analysis. Due to these differences, methods for AOI analysis are unsuited to handle DOI data, and new analytic methods are necessary.  

This paper provides the necessary ingredients for such work. Our contributions are: (i) a formal definition of DOI analysis, data model and examples of DOI in multiple domains (Section~\ref{sec:DataModel}) ;( ii) a task-taxonomy for DOI-based visualization (Section~\ref{sec:Taxonomy}); (iii) a demonstration of existing visualization techniques in context of DOI-based visualization (Section X3);(iv) limitations of using DOI analysis (Section~\ref{sec:Limitations}). 

