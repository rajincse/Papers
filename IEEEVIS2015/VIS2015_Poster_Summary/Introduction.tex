\section{Introduction}

Eye-trackers can tell us where on the screen computer users are looking, and have been used extensively as diagnostic tools in disciplines such as psychology, cognitive science, human-computer interaction, and Visualization research~\cite{duchowski2002breadth}. Traditional eye-tracking analyses, such as point-based analysis and area of interest (AOI) analysis~\cite{blascheckstate}, rely on gaze coordinates collected in conjunction with rendered visual stimuli, and require a significant amount of manual input from human annotators to relate gazes to the semantic meaning of the stimuli~\cite{alamdata}. Such efforts meant that eye-tracking analyses could only be performed relatively laboriously, offline. 

While this may have been acceptable while eye-trackers were expensive and data relatively difficult to collect, accesible eye-trackers (e.g., Tobii EyeX) open up novel analysis possibilities. One of these is analyzing eye-tracking data in real-time. For example, it is nowadays conceivable that classroom computers could be equipped with eye-trackers, and visual learning environments instrumented to capture in detail what learning concepts students are looking at. Such data could be used in real time by instructors, to identify students that donâ€™t tend to concepts known to be important or fail to make progress, and provide proactive help. 

Recently, Alam et al.~\cite{alamdata} proposed the data of interest (DOI) analysis of eye-tracking data. This approach simplifies the collecting and analysis of eye tracking data to the point that it can be performed in real time. It involves instrumenting the rendering code of a visualization so that gazes  are automatically related to the visual content that is displayed on the screen. DOI-based analysis of eye-tracking data works on the data-space instead of image space. DOI-based analysis method can be instrumented in the visualization system. The method provides fuzzy scores of elements which viewers are probably put their interest. 

We demonstrate our method of automated information retrieval from eye-tracking user study data we conducted a meta user study over the user study data-set from Alam et al.~\cite{alamdata}. More in-depth description of the meta user study is provided in Section~\ref{sec:Evaluation}. 
 
