\section{Related Work}
Eye-tracking can locate users' gazes on a computer screen~\cite{ware1987evaluation, jacob1991use} and is a technology that is becoming increasingly accurate, fast, and affordable~\cite{duchowski2007eye, sesma2012evaluation}. Eye-tracking is often used to record peoples' gazes while performing tasks that involve visual stimuli, and analyzing the data off-line to gain insight into how people interpreted the stimuli and solved the tasks~\cite{duchowski2007eye}. For example, eye-tracking was used to understand how people perceive faces~\cite{guo2014perceiving,shasteen2014eye}, to study how attention changes with emotion~\cite{vervoort2013attentional}, to understand changes in perception that are caused by disease~\cite{kim2014investigating}, and to gain insight into how students use visual content to learn~\cite{zawoyski2014using,mayer2010unique,van2010eye,conati2013eye}. Within the field of data visualization, examples of eye-tracking studies include but are not limited to work by Pohl et al. and Huang et al. on graph readability~\cite{pohl2009comparing,huang2008beyond,huang2005people}, Burch et al.'s work on tree-drawing perception~\cite{burch2011evaluation,burch2013visual}, and work by Kim et al. on evaluating an interactive decision making visualization~\cite{kim2012does}.
 
Eye-tracking data is traditionally interpreted and analyzed in the space of rendered visual stimuli that gazes were recorded for, using one of two analysis paradigms: point based or area of interest (AOI) based~\cite{blascheckstate}. Point based analyses treat gaze samples or fixations as independent points while AOI analyses first aggregate gazes into areas of interest and then operate at this higher level of abstraction. Most often, experimenters define AOIs manually, but gaze clustering algorithms are also available to automatically define AOIs based on the available eye-tracking data~\cite{privitera2000algorithms,santella2004robust,drusch2014analysing}. 
Our work is closest to a sparse set of methods that seek to automatically relate gazes to the semantics of computer generated content. Several papers allude to the fact that AOIs could be defined dynamically for such cases~\cite{steichen2013user,kurzhals2014iseecube}. More concretely, for dynamic stimuli with known 3D structure, researchers have explored the concept of objects of interest (OOI), in which gazes are automatically assigned to 3D objects in the scene~\cite{stellmach20103d}. More recently, Bernhard et al. looked at similar gaze-to-object mapping in the context of understanding what people were looking at in virtual 3D environments~\cite{bernhard2014gaze}. Our work presents a more detailed account of how gazes can be automatically assigned to content typical of 2D information visualization and evaluate how effective this can be.
 
Moreover, our method of detecting viewed objects improves over na\"{\i}ve methods by leveraging Salvucci's ``intelligent gaze interpretation'' paradigm~\cite{salvucci1999inferring,salvucci2000intelligent}. Specifically, Salvucci found that simply assigning gazes to an object if the gazes' coordinates are within the bounds of the object is insufficient, and that leveraging the semantics of visual content can significantly improve our ability to predict which objects are viewed. More recently, Okoe et al. found similar results, albeit using a different method~\cite{okoe2014gaze,okoe2using}. We extend on such work by presenting an intelligent gaze interpretation' algorithm that is tailored to content typical of data visualization and by evaluating it.
 
Finally, the visualization community proposed a plethora of visualization and visual analytics tools for both point-based and AOI based eye-tracking analysis. Blascheck et al. provides a comprehensive review of such methods~\cite{blascheckstate}. Most relevant to our work are methods for AOI visualization, since our data is in essence a highly granular and annotated AOIs data. Popular examples of such techniques include scarf plots~\cite{richardson2005looking}, AOI rivers~\cite{burch2013aoi}, and AOI transition matrices~\cite{goldberg1999computer}. Also relevant are visual analytics principles and systems for analyzing AOI data, such as work by Andrienko et al.~\cite{andrienko2012visual}, Weibel et al.~\cite{weibel2012let}, and Kurzhals el al~\cite{kurzhals2014iseecube}. However, the data our instrumentation allows us to collect differs somewhat from regular AOI data through its high granularty, connection with the underlying data of visualizations, and uncertainty about whether an object AOI was truly viewed. Moreover, the focus of the work we present here is not in proposing novel techniques of analyzing data collected in visualization and data space, but on whether and how this can be done accurately and whether it is beneficial.

