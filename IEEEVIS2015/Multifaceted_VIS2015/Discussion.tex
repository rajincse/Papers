\section{Discussion}
\label{sec:Discussion}
\subsection{Benefits}
\label{sec:Benefits}

It took each of our coders approximately six hours to produce a detailed and accurate coding of just twelve minutes of user data ($6$ subjects $\times$ $2$ minutes). This illustrates the importance of moving beyond interpreting eye-tracking in stimulus space. The instrumentation we described and evaluated makes it feasible to analyze eye-tracking data from many subjects, using highly interactive content, for long analysis sessions. Such analyses can be done immediately after or even as the data is collected since no manual annotation of the data is required. Moreover, the collected data has semantic meaning that is tied to the underlying data of the visualization and is thus amenable to a much richer set of visual and computational analyses than traditional eye-tracking data. The analyses that our approach facilitate, such as those exemplified in sections X and Y, focus on data and concepts, and are thus significantly different from current eye-tracking analyses which generally aim to understand visual perception and low level visual strategies in static visualizations.

Our field currently lacks a quantitative method to explore questions related to how users perceive visualizations in general, how domain experts look at particular types of data, and how analysts use visualization to search for relevant data and aggregate them into hypotheses. Visualizations researchers often have to rely solely on discussions with domain experts, think aloud studies, and recordings of user activity, all of which provide qualitative data and often require additional coding and interpretation. Our work provides a novel framework to explore such questions quantitatively and can thus play an important role in advancing the visual analytics agenda~\cite{thomas2006visual}.

\subsection{Applications}
\label{sec:Applications}
The benefits described above render our approach potentially useful in understanding how users forage for, integrate, and hypothesize about data using complex, domain specific, visualization systems. For example, visual analytics applications could be instrumented to facilitate the exploration of domain expert workflows, of how expertise influences data search and analysis patterns, and of visual strategies and data associated with successful hypothesis generation and testing. Similarly, the instrumentation of visual learning environments could lead to insight into how students learn and what makes some learners more effective than others. Given the proliferation of education through visual, interactive environments, particularly as part of massive MOOC instructions, this could have significant impact. 

In both aforementioned cases, the data can also explain how visualizations support analysis, discovery, and learning. For example, given a particular domain, we could quantify which data can answer which questions, what types of data are often used together, and how visual widgets are viewed in an analysis process.  The quantitative analysis described in Section~\ref{sec:Evaluation} exemplifies this. Such analyses would both advance our understanding of how visualizations work, and, more practically, suggest design changes that could make visualizations more efficient. 

More differently, viewing data collected automatically during a user's session could be used directly to support that user's workflow. For example, the data could be used to create summaries that capture the user's activity during a day, week, or month. Such summaries could be used to refresh the user's memory at a later time, communicate progress to peers or supervisors, or provide useful hints to other users or analysts exploring similar questions in similar data-sets.

Detecting viewed objects in-real time also opens up two specific opportunities. First, analyzing eye-tracking data in real-time could be used in teaching. Instrumenting learning environment would allow instructors to track students' progress in a lab assignment in real-time, to detect students that are not tending to elements crucial for solving or understanding the assigned problems, and to provide help proactively. Second, it would allow us to create a new generation of gaze-contingent visualizations. For example, visualizations could detect in real-time data that is of particular interest to a user and make recommendations of unexplored data with similar attributes, or could visually emphasize a user's current set of working objects and de-emphasize data, and even views, that a user never shows interest in. 

\subsection{Limitations}
\label{sec:Limitations}
Our approach is restricted to visualizations with open source code and as such cannot be used to automate the full spectrum of current eye-tracking studies (e.g., analysis of real imagery or of commercial systems).   This problem however is to some degree inherent to software and hardware instrumentation: whether one wishes to capture an application's interaction data, a website's activity, or a network's throughput one needs privileged access to those systems. Thus, like most instrumentations, our approach is intended primarily for creators or owners of data visualizations who wish to understand how their users use their visualizations, and to discover changes that could make their visualizations more efficient. Moreover, our approach creates additional analysis and interaction opportunities, a few of which we exemplified in Section~\ref{sec:Methods}. 

Second, instrumenting visualization by altering its source code and defining transition and viewing probabilities involves an overhead. Again, this is a problem with instrumentation in general. Ultimately the overhead of instrumenting a specific visualization must be offset by the benefit of collecting the data, and thus the opportunity of instrumenting a visualization has to be decided on a case by case basis. For example, if the development of a visual analytics system takes a year from requirements elicitation to final implementation, spending even an extra week to mirror the rendering code with an instrumentation library may seem warranted, especially if it allowed the developers to gain significant insight into how the system is used. Our future plans include the bundling of the methods we described into an instrumentation library, which would reduce the cost of instrumenting a visualization significantly (Section~\ref{sec:InstrumentingVisualization}). 

Finally, picking the right parameters our probabilistic algorithm relies on might be somewhat difficult since our community doesn't yet have a sufficiently solid grasp on how users parse and interpret visualizations to provide useful guidelines for picking those parameters. To address this, in section X we give a methodology to quantify transition and viewing probabilities from real data collected from users. Such computations could be performed during a pilot studying to reveal usage patterns in a particular visualization. Furthermore, we believe visualizations are rarely used in a random fashion and that specific tasks and visual outputs elicit certain gaze patterns. In section X we demonstrate that this is true for the particular visualization we analyzed. We believe that further research could lead to a more general understanding of the probabilities our algorithm relies on and that our work provides a framework to facilitate such research. We discuss our plans in this direction in Section~\ref{sec:FutureWork}. 

\subsection{Performance gains by using a probabilistic approach}
An important merit of our work was to show that by integrating an understanding of how users use a visualization (algorithm 3) we can detect objects more accurately than by just relating gazes to visual object geometry (algorithm 2). While in our particular example the gain was relatively small, we think that this analysis is very dependent on the type of visualization in questions, and that some visualizations will benefit significantly more from the approach. 

Table~\ref{tab:TransitionFromMovie} suggests that there can be very strong biases in how people use visualizations (e.g., subjects were X times more likely to view a highlighted item connected to a previously viewed item, than they were to view a random item). We believe this to be generalizable to many visualizations, especially those that show large, heterogeneous data, since this means that the same data are likely to be used differently based on context and task, and which are intended for focused analyses, since, as shown in section X, a task can significantly constrain what data is viewed.  

The degree to which such viewing patterns can and need to be leveraged depends on a visualization's  configuration. For example, in our visualization the different data categories (i.e., movies, directors, actors) were spatially separated in different panels. As such, if there were multiple potential viewing targets concurrently, they were generally all of the same type. This means that our algorithm never got the chance to use object category as a discriminator. Instead, in a traditional node link diagram multiple definable categories of nodes share the same space, and are distinguishable by some visual attribute or semantic meaning (e.g., proteins in a protein interaction network can be kinases, receptors, etc.). In such a case, an algorithm could use knowledge such as that a user is currently scanning for, or generally more interested in, a particular type of node, to distinguish between nodes of different categories that are placed next to each other.  

More generally, a visualization will benefit more from our predictive approach if heterogeneous content is cluttered and shares the same space, and the visualization relies on visual and semantic cues to enable the user to select subsets of  data that are relevant to a particular task or analysis. Such visualizations are fairly commonly used in real, domain specific visualization applications. Examples include: x,y,z. Instead, if the visual content is sparse and well separated, then computing gaze scores alone would be sufficient and our algorithm's predictive component would not create any benefit.


\subsection{Evaluating viewed object detection} 

The above mentioned variability in determining the performance gain that can be achieved through intelligent instrumentation makes it hard to assess the real impact of the method. Moreover, comparing our results to human coders is questionable in terms of evaluating our prediction algorithm since, if coders look primarily at momentary gaze positions, rather than trying to understand what users are trying to do overall, then their annotation may be closer to our raw gaze scores rather than scores that integrate prediction.  This latter problem raises an issue about whether human coders can provide a robust ground truth for evaluating techniques such as ours, and whether such ground truths may be improved if eye-tracking data was collected in conjunction with a think-aloud protocol.  

First, we note that we see the quantitative evaluation described in Section~\ref{sec:Evaluation} as an evaluation against the state-of-the –art rather than against a ground truth. In other words, we don't claim that our method produces results that are accurate with respect to what people actually looked at. Instead, we claim that our method allows us to analyze the data in the same way a human could, only much faster. 

Second, we believe that striving towards a reliable ground truth is slightly misguided in the context of evaluating eye-tracking instrumentation.  People often view elements even without consciously realizing it, since vision is by-and-large a subconscious process~\cite{duchowski2007eye}. People also are able to register multiple objects in fixated region, even though not fixating them specifically. For example, while reading people often skip short words or syllables, while still registering the fact that they are there. This in fact leads to an interesting question about whether we track what a subject looks at or what a person sees. Finally, people also occasionally stare at visual objects while in fact thinking of something else~\cite{duchowski2007eye}. 


As such, we believe a clean ground truth that represents what a subject actually looked at is either unattainable or, if obtained through think allowed protocols, would not be representative of real-life usage scenario. Specifically, we hypothesize that should experimenters ask subjects to state what they are looking at, or look at particular objects, this would change not only what items subjects look at, what also how they look at them in terms of low level gaze patterns (e.g., subjects may tend to fixate closer to or directly on an object). Such artifacts are known to occur when using think-aloud protocols, and we think they would be even more prevalent due to the subconscious, intuitive, and fast nature of visual perception.  Evidence for this is given by Ogolla who showed that current think-aloud protocols changes visual patterns recorded by an eye-trackers, especially for exploratory, low-information tasks~\cite{ogolla2011usability}.
 

Finally, we believe our second type of evaluation, described in Section~\ref{sec:EvalDataCollected}, is in fact an evaluation against a higher level ground truth. Our tasks, especially the structured ones, dictate what users will have to look at in order to solve the tasks, and the two visual representations in Figures~\ref{fig:heatmap} and Figure~\ref{fig:RelevanceDiagram}, indicate how close our instrumentation method comes to that ground truth. While these ground truths are somewhat approximate and not sufficiently detailed to capture the small differences between instrumentation algorithms, we believe they are well suited at evaluating approaches such as ours.   

\subsection{Future Work}
\label{sec:FutureWork}
We hypothesize that there is a set of general principles about how people take in visual and data content that are valid across visualizations. For example, most visualizations have a mechanism for highlighting specific elements either through interaction or through queries and we show that this highlighting matters in how people view elements. Second, while we studied connected elements in the context of a node-link like diagram, establishing a visual connection between elements is a common visualization mechanism and can be found in the use of  brushing and linking or leader lines; we think our finding that users tend to view connected elements together may apply to such cases as well. Third, most data featured in visualization can be divided into semantic groups (e.g., actors, movies, directors; protein kinases, protein receptors; conference papers, journal papers) and we hypothesize that viewing transitions between and within such categories are also not random. Finally, we show that in our particular example users identified data that is highly connected to their task and then shifted their attention repeatedly and almost exclusively within that data group. We believe this is a behavior that may also be generalizable. Demonstrating these generalities and exploring other patterns is beyond the scope of. Our automated data collection approach and the methodology described in section x would allow us to explore and quantify such patterns in other visualizations. This would both deepen our understanding of how visualizations are used and provide guidelines for choosing appropriate inputs to our algorithms. 

More work is also needed to understand the impact of different parameters involved in viewed object detection. For example, how far away from an item can a user fixate and still be considered to be viewing the item? The parameter that captures this in our algorithm is $R$, and, while we use a constant $R$ for all items, this is unlikely to be an optimal approach. Based on qualitative observations of our collected data and knowledge of the interplay between peripheral vision and the fovea~\cite{balas2009summary}, we believe users fixate close to items if they are surrounded by clutter,  but exhibit significantly more variability if items are isolated. Thus, we hypothesize that $R$ should adjust itself dynamically based on the clutter of the region that a user is fixating.  A further question is whether $R$ should be changed based on the visibility or discriminating features of an item: can subjects fixate farther and still perceive an item, if that items is large enough? Current models of peripheral vision state that clutter is a more determining factor in peoples' ability to use their peripheral vision~\cite{balas2009summary}, but further research is required to quantify the effects of such algorithmic instrumentation choices.  

Additional work is also needed to understand how to and whether we can detect visual objects other than nodes or labels, such as for instance polylines in a parallel coordinate plot, contours in a group or set visualization, or cells in a heatmap. It is unclear how to compute a gaze score ($gs$) for such objects since there is no research to describe how people fixate them. 

Finally, our future plans include the bundling of the methods we described in this paper into an instrumentation library that would reduce the cost of instrumenting a visualization. Specifically, a developer would be able to register visual objects, together with their geometry, to this library. They would then need to maintain a correspondence between what is shown on the screen at any given time and visual objects registered with the instrumentation library. Thus, when a new object is added to or removed from the screen, or when its position or shape changed, these would need to be registered with the library, a workflow that integrates well with the add-remove-update pattern of D3. Additionally, developers would create classes of objects, for instance based on based on data semantics (e.g., kinases, movies, actors) or visual aspect (e.g., highlighted, glyphs of a certain kind), and specify transitions probabilities between them. The library would implement the algorithms described here and provide in real time a list of visual items being viewed.   