\section{Introduction}
Eye-tracking is a method of reporting eye activity using special eye-tracking hardware. Typically, eye-tracking devices can pin-point where a person is looking at a display device (e.g. computer screen, projection screen, handheld, and wearable displays).While eye-tracking can be used both as a diagnostic tool and an interactive input device, this dissertation will primarily focus on the former. In its diagnostic capacity, eye-tracking technology generally serves the purpose of quantitatively measuring people’s attentional process as they solve visual tasks. It plays a major role in research fields such as human-computer interaction, cognitive sciences, and information visualization.  In a typical diagnostic eye-tracking experiment, a human subject is placed in front of a computer screen which shows a visual stimulus. Meanwhile, an eye-tracking device (i.e. eye-tracker) reports and records the subject’s gaze positions on the screen. Experimenters then test their hypotheses by analyzing the collected data using visual and statistical analytics techniques.  

Presently, eye-tracking data, collected as a stream of 2D gaze-samples, is analyzed by one of two approaches: point-based and area of interests (AOI)-based analysis. In point-based methods, gaze samples are treated as individual points that are related to the 2D stimulus shown on the screen when the samples were collected. In AOI-based methods, experimenters first define certain regions or areas within the analyzed 2D stimuli. Gaze samples are then binned into those regions or AOIs, which then serve as a higher-level unit of analysis.  

A major limitation of these approaches is that both of them involve a significant overhead: gaze samples are collected as pixel coordinates and experimenters relate them to the visual stimulus by either overlaying gaze-clouds on top of the stimulus image (e.g. heatmap), or by having to manually define AOIs. However, if the stimulus is dynamic or interactive then these analysis actions have to be repeated for each frame of stimulus. This makes such approaches infeasible for dynamic or interactive stimuli. 

A solution presents itself with the realization that in data visualizations the arrangement and layout of visual contents are known at rendering time. Hence, for visualizations with accessible source-code, this can be instrumented so that gaze samples are related to visual contents automatically and in real-time. In other words, we can track what data objects users are viewing at each consecutive moment in time. For example, a network visualization may visual representations of nodes and edges. Since we know where these data objects are drawn on the screen, we can map gaze-samples provided by an eye-tracker to them. To exploit the analogy with the established AOI nomenclature, we call such eye-tracked data objects Data of Interest (DOI), and the entire detection and analysis process DOI eye-tracking analysis. 

The particularity of DOI analysis is that it can be performed in data space rather than image space. In other words, DOIs are coupled with visualization data. Thus, they can be annotated with data attributes. As a result, DOIs can be analyzed independently from visual stimuli. Hence, it will eliminate manually relating gaze samples to visual stimuli process which is regularly performed in traditional analysis methods (i.e. point-based and AOI-based). Moreover, DOI analysis will support experiments of significantly longer sessions that traditional analysis approaches can operate. Again, operating in data space will leverage DOI analysis to answer many questions that traditional analysis approaches cannot. 
As part of this dissertation, we seek to create the foundation for DOI eye-tracking analysis (i.e. DOI analysis) data. Our research goals will be achieved by the two contributions below:
